# llm-fav-resources
A curated list of favorite resources and readings related to LLMs. 

## Talks



## Papers
* [The Surprising Effectiveness of
Test-Time Training for Abstract Reasoning](https://ekinakyurek.github.io/papers/ttt.pdf") Using ideas from test-time training in Computer Vision, synthesize examples to exploit test-time compute to fine-tune the model. Tackles the Arc Challenge showing improvements over plain fine-tuned models.
* [Training Large Language Models to Reason in a
Continuous Latent Space](https://arxiv.org/pdf/2412.06769)
Training models to reason in latent space by taking last token embedding and feeding it back to the model without performing next word prection for a number of steps. Training is done by masking out output tokens one by one in each stage, instead allowing model to use latents and generate next latents freely.


